{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Memory Systems\n",
    "\n",
    "* Large class defined by memory model\n",
    "  * And thus, the programming model\n",
    "* In shared-memory programming, \n",
    "  * parallel _threads_ \n",
    "  * exchange information through reads and writes to shared memory.\n",
    "  * synchronization constructs  control sharing\n",
    "* Easy to use abstraction\n",
    "* Examples\n",
    "  * OpenMP, Java, pthreads, C++ threads\n",
    "  \n",
    "<img src=\"https://computing.llnl.gov/tutorials/parallel_comp/images/uma.gif\" width=\"512\" title=\"Uniform Shared Memory System\" />\n",
    "\n",
    "### SMP = Symmetric Multiprocess\n",
    "\n",
    "* Simplest form of shared-memory MIMD system in which \n",
    " * All processors can address all memory\n",
    " * Symmetric performance (latency and throughput) from all processors to all memory addresses\n",
    "* SMPs have scaling limits\n",
    "  * physics makes it difficult to maintain symmetry as we add cores to processors or processors to machines.\n",
    "  \n",
    "Few (or no) machines end up being symmetric in practice.  Let's consider:\n",
    "  * a two processor machine with symmetric access to memory\n",
    "  * each processor has 4-cores with symmetric access to an L3 cache\n",
    "As the program runs data ends up cached in memory, L3 and higher-level caches.  Processors have assymetric access to data in an L3 cache.  Cores have assymetric access to data in core-private caches.\n",
    "\n",
    "Highly-optimized programs must consider l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
